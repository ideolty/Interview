# 综述

# 事务

## TCC分布式事务



这个讲的非常好，思路讲的很清楚了

//todo 分析一个具体的tcc框架

[拜托，面试请不要再问我TCC分布式事务的实现原理！](https://juejin.im/post/5bf201f7f265da610f63528a)



## 2pc 



## XA



//todo 有一个个人网站总结的很好，需要找一下



# 锁



说来说去就是一个，需要把锁细化，用分段锁，别一把锁锁住全部的数据。



[每秒上千订单场景下的分布式锁高并发优化实践！【石杉的架构笔记】](https://juejin.im/post/5bf6b40de51d4536656f1f28)



## 基于zookeep

## 基于redis

//todo



# 唯一id生成算法

1. 独立数据库自增id

   每次要生成一个id，都是往一个独立库的一个独立表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个id。拿到这个id之后再往对应的分库分表里去写入。

   - 好处就是方便简单，谁都会用。

   - 缺点就是单库生成自增id，要是高并发的话，就会有瓶颈的。

2. uuid

   uuid太长了，作为主键性能太差了，不适合用于主键，而且没有顺序性。

3. 系统当前时间

   - 并发很高的时候，比如一秒并发几千，会有重复的情况。
   - 将**当前时间跟很多其他的业务字段拼接起来，作为一个id**也可以



4. snowflake

   其核心思想就是：使用一个64 bit的long型的数字作为全局唯一id，这64个bit中，其中1个bit是不用的，然后用其中的41 bit作为毫秒数，用10 bit作为工作机器id，12 bit作为序列号。






[高阶Java开发必备：分布式系统的唯一id生成算法你了解吗？【石杉的架构笔记】](https://juejin.im/post/5c6be4086fb9a04a060570df)



# 缓存

缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级等概念

> #### 缓存雪崩

由于原有缓存失效，新缓存未到期间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。



1. 考虑用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。

   很少使用。加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。在高并发下，缓存重建期间key是锁着的，这是过来1000个请求999个都在阻塞的。同样会导致用户等待超时，用户体验很差。

2. 设置过期标志更新缓存

   每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。当缓存标记key过期后，实际缓存还能把旧数据返回给调用端，直到另外的线程在后台更新完成后，才会返回新缓存。

   或者说可以模仿eruka的做法设计多层缓存，`readOnlyCache`、`writableReadCache`。失效时间错开即可。

3. 将缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。



> #### 缓存穿透

缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。

1. 最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。
2. 另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴！



> #### 缓存预热

缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！

1. 直接写个缓存刷新页面，上线时手工操作下；

2. 数据量不大，可以在项目启动的时候自动进行加载；
3. 定时刷新缓存；



> #### 缓存更新

1. 预估失效时间

2. 版本号（必须单调递增，时间戳是最好的选择）

3. 提供手动清理缓存的接口。



主动更新：

1. 先更新缓存，后更新DB。

   ```
   t1更新缓存；
   t2读缓存，因为t1把缓存更新了，导致t2没读到。从db中读，然后更新缓存；
   t1更新DB。
   
   上述操作系列会导致缓存脏数据。
   ```

2. 先更新DB，后更新缓存。

   ```
   t1更新DB；
   t2更新DB；
   t2更新缓存；
   t1更新缓存。
   
   上述操作系列同样会导致缓存脏数据。
   ```

   无论谁先谁后，只要更新缓存和更新DB不是原子的，就可能导致不一致。只是从实际业务来讲，一般缓存也都是保持“最终一致性“，而不是和DB的强一致性。

   并且一般建议先更新DB，再更新缓存，优先保证DB数据正确。


解决策略：

1. 业务方（调用者）更新。传统上，更新缓存都是由业务方来做，也就是由调用者负责更新DB和缓存。
2. DB中间件监听DB变化，更新缓存。现在有种新的办法就是利用DB中间件监听DB变化（比如阿里的Canal中间件，点评的Puma），从而对缓存进行更新。这种办法的一个好处就是：把缓存的更新逻辑，和业务逻辑解藕。业务只更新DB，缓存的更新被放在另外一个专门的系统里面。
3. 使用数据库触发器





[分布式缓存--序列4--缓存更新策略/缓存穿透/缓存雪崩](https://blog.csdn.net/chunlongyu/article/details/53384933)



> #### 缓存降级

当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：





> #### 多层缓存的问题

//todo

[如果20万用户同时访问一个热点缓存，如何优化你的缓存架构？【石杉的架构笔记】](https://juejin.im/post/5c448670e51d455bd36b67f9)







# 系统设计存在问题

## 1. active-standby高可用架构

- 分布式系统中要避免**单点故障**，这个问题要解决，可以考虑集群，也可以考虑热备。

- 热备的话可以考虑使用zookeeper。如果active节点宕机，那么standby节点感知到，会自动切花为active，同时自动读取他们共享的一个计算引擎的中间状态，然后继续恢复之前的计算。

- 本身zookeeper的读写性能非常的高，而且zookeeper集群自身就可以做到非常高的可用性，同时还提供了大量的分布式系统需要的功能支持，包括**分布式锁**、**分布式协调**、**master选举**、**主备切换**等等。



## 2. Master-Slave架构的分布式计算系统

数据平台系统其实最核心的任务就是对一个一个的任务中的数据进行计算，但是随着每天的日增数据量越来越多，每个任务内的数据量也会越来越大，同时会导致数据平台系统的计算负载越来越高。



- 首先我们将数据平台系统彻底重构和设计为一套分布式的计算系统，将**任务调度**与**任务计算**两个职责进行**分离**
- 有一个专门的Master节点负责读取数据，生成相应的计算任务，然后将各个计算任务分发给多个Slave节点。
- Slave节点的任务就是专门接收一个一个的计算任务，每个计算任务就是对一个数据分片执行一个几百行到上千行的复杂SQL语句来产出对应的数据分析结果。
- 同时对Master节点还需要进行集群架构或者说双机热备，避免单点故障。



## 3. 弹性计算资源调度机制

就是从机的**负载均衡**。某个计算任务耗时过长，导致某台Slave机器积压了大量的计算任务一直迟迟得不到处理。原因有很多可能是系统的高峰和低谷的数据差异、单个任务数据量过大计算任务太重、不同类型的任务处理时间不同等等。所以需要设计一个可以主动感知从机负载状态的任务调度策略。



可以考虑在Master节点中加入计算任务metrics上报、计算任务耗时预估、任务执行状态监控、机器资源管理、弹性资源调度等机制。

- Master节点会实时感知到各个机器的计算任务执行情况、排队负载压力、资源使用等情况。

- 同时还会收集各个机器的计算任务的历史metrics

- 接着会根据计算任务的历史metrics、预估当前计算任务的耗时、综合考虑当前各Slave机器的负载，来将任务分发给负载较低的Slave机器。



## 4. 分布式系统高容错机制

这里的容错只考虑任务调度和任务处理，那么可能产生的问题包括但不限于：

- 某个Slave节点在执行过程中突然宕机
- 某个计算任务执行时间过长
- 某个计算任务执行失败



因此，Master节点内需要实现一套针对Slave节点计算任务调度的容错机制，大体思路如下：

1. Master节点会监控各个计算任务的执行状态，同时也会监控各个Slave节点的运行状态
2. 如果说某个Slave宕机了，那么此时Master就会将那个Slave没执行完的计算任务重新分配给其他的Slave节点
3. 如果说某个Slave的计算任务执行失败了，同时重试几次之后还是失败，那么Master会将这个计算任务重新分配给其他的Slave节点来执行
4. 如果说某个计算任务在多个Slave中无法成功计算的话，此时会将这个计算任务储存在一个延时内存队列中，间隔一段时间过后，比如说等待高峰期故去，然后再重新尝试执行这个计算任务
5. 如果某个计算任务等待很长时间都没成功执行，可能是hang死了，那么Master节点会更新这个计算任务的版本号，然后分配计算任务给其他的Slave节点来执行。
6. 之所以要更新版本号，是为了避免说，新分配的Slave执行完毕写入结果之后，之前的那个Slave hang死了一段时间恢复了，接着将计算结果写入存储覆盖正确的结果。用版本号机制可以避免这种情况的发生。





## 5. mysql

所有的计算都压在了mysql数据库上，**数据的存储和计算**混在了一个地方，都在同一个MySQL库里 。可以采取下面思路：

- 数据直接写入一个存储，仅仅只是简单的写入即可，简单存储可以考虑hbase等
- 然后在计算的时候从数据存储中提取你需要的那个数据分片里的可能就一两千条数据，写入另外一个专用于计算的临时表中，那个临时表内就这一两千条数据
- 然后运行你的各种复杂SQL即可



之后可以把sql运算从mysql中解放出来，使用**纯内存的SQL计算引擎**。完全干掉mysql。



## 6. MQ

MQ削峰以及流量控制。

我们如果应对的是高并发的**非实时响应的**写入请求的话，完全可以使用MQ中间件先抗住海量的请求，接着做一个中间的流量分发系统，将流量异步转发到存储中去，同时这个流量分发系统可以对高并发流量进行控制。

比如说如果瞬时高并发的写入真的导致后台系统压力过大，那么就可以由流量分发系统自动根据我们设定的阈值进行流量控制，避免高并发的压力打垮后台系统。

而且在这个流控系统中，我们其实还做了很多的细节性的优化，比如说数据校验、过滤无效数据、切分数据分片、数据同步的幂等机制、100%保证数据落地到数据库集群的机制保障，等等。



## 7. 数据的动静分离架构

如果你的SQL要对一些表进行关联计算，里面涉及到了一些大部分时候静态不变的数据，那些表的数据一般很少改变，因此没必要每次都走网络请求从存储里提取那部分数据，我们其实完全可以在Slave节点对这种静态数据做个轻量级的cache，然后只有数据分片里对应的动态改变的数据才从kv存储来提取数据。







[亿级流量系统架构之如何设计承载百亿流量的高性能架构【石杉的架构笔记】](https://juejin.im/post/5bfd2df1e51d4574b133dd3a)





# OAuth2.0



# 下载

方案是授权码模式





# 引用

[亿级流量系统架构之如何设计高容错分布式计算系统【石杉的架构笔记】](https://juejin.im/post/5bfbeeb9f265da61407e9679#heading-2)
















7、重连机制会不会造成错误可以实现？

19、列举出你能想到的数据库分库分表策略；分库分表后，如何解决全表查询的问题



